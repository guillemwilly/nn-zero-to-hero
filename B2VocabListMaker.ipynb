{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeVNpY7phl2CtqroLYd/md",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guillemwilly/nn-zero-to-hero/blob/master/B2VocabListMaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##This program takes as an imput a book in the form of a text file and produces a list of words ordered by frequency corresponding to the CEFR (A1 to C2) level indicated by the user.\n"
      ],
      "metadata": {
        "id": "j9iXiuPELodu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "-ZamUhkKQG9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cc1e7a-e29f-4963-f82e-5a53737d1420"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### here we dont need many packages just spacy and panda as well as io to pass the correct data type to the panda functions"
      ],
      "metadata": {
        "id": "qls1-1xFbkwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "41wgm-xtL3dF"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ],
      "metadata": {
        "id": "K71OkXrINu8b"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we just define a funtion called \"scraper\" which is just gonna take the file fom the given url and take the data here I also have it cleaning up the opening paragraph of the data I am using"
      ],
      "metadata": {
        "id": "6dOMYGMxcQhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scraper(url):\n",
        " # scrape url\n",
        "  response = requests.get(url)\n",
        "  text = response.text\n",
        "  # delete the opening paragraph\n",
        "\n",
        "  num_lines_to_delete = 12\n",
        "\n",
        "\n",
        "  lines = text.split('\\n')\n",
        "\n",
        "  # delete the lines\n",
        "  clean_text = '\\n'.join(lines[num_lines_to_delete:])\n",
        "\n",
        "  # return\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "1asbo6uyOFUL"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we call the function that we just defined."
      ],
      "metadata": {
        "id": "L1mp-8IXcaH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://www.wordfrequency.info/files/spanish/spanish_lemmas20k.txt\"\n",
        "word_freq = scraper(url)\n",
        "\n",
        "print(word_freq)"
      ],
      "metadata": {
        "id": "KzynpreWOq_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## now we create the panda data frame to make the data easier to compare to in the later algorthithm"
      ],
      "metadata": {
        "id": "pOIjJrxBca0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a panda data frame\n",
        "\n",
        "# create data frame\n",
        "columns = [\"ID\", \"freq\", \"lemma\", \"PoS\"]\n",
        "df = pd.read_csv(StringIO(word_freq), sep = '\\s+', skiprows = 2, names = columns)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "l9qvyZTcbZ9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using the Panda Data frame created we can then look to tokenize a text in our target language which is Spanish here. Here we call the file for the Book we are using and store it in the variable \"book_text\""
      ],
      "metadata": {
        "id": "t6i4o230hN1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Book_Collection/book.txt\", \"r\") as file:\n",
        "  book_text = file.read()\n",
        "\n",
        "  print(book_text)"
      ],
      "metadata": {
        "id": "LjZq1bwMhpj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now I will process the book using Spacy to tokenize it so that it can be worked with easily. Within the function is a lemmatizer and a function to make the word lowercase, this is to avoid cases where case or grammatical morphemes might make the algorithm miss any coincidences."
      ],
      "metadata": {
        "id": "E9G8wtUrn5vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter words in the book based on the frequency\n",
        "def filter_words(text):\n",
        "    # Use spacy to create an NLP object\n",
        "    doc = nlp(text)\n",
        "    # Extract words with frequency greater than the pre-established threshold and lemmatize\n",
        "    filtered_words = [token.text.lower() for token in doc if token.lemma_.lower() in df[df['ID'] > 4991]['lemma'].tolist()]\n",
        "    return filtered_words\n",
        "\n",
        "filtered_words = filter_words(book_text)\n",
        "\n",
        "print (filtered_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqkEAk5voMGl",
        "outputId": "bafc693d-ac0a-4210-c3d1-189eae68206e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prólogo', 'mugrientos', 'intersticios', 'o', 'o', 'rellenan', 'según', 'ciudadela', 'chorrean', 'volados', 'estampas', 'moscas', 'labradores', 'carpinteros', 'labradores', 'carpinteros', 'apasionadas', 'ciudadela', 'taberna', 'ciudadela', 'francia', 'labrador', 'capitaneaba', 'bárbaras', 'espontáneamente', 'ladrón', 'ladrones', 'maltrecho', 'o', 'taberna', 'taberna', 'o', 'feo', 'ladrón', 'vagabundo', 'veleidades', 'según', 'ciudadela', 'ciudadela', 'lagartos', 'comarca', 'párroco', 'ladrido', 'péndulo', 'olfateando', 'taberna', 'o', 'vagabundo', 'ciudadela', 'ciudadela', 'taberna', 'mostrador', 'taberna', 'taberna', 'divergencias', 'taberna', 'azuzaba', 'o', 'o', 'graciosa', 'taberna', 'excitado', 'o', 'adjetivo', 'campeaba', 'lobos', 'lobo', 'venerable', 'blasón', 'hondonada', 'según', 'catalina', 'débil', 'evangélica', 'costillas', 'desliz', 'catalina', 'privilegiada', 'catalina', 'o', 'catalina', 'o', 'ladrón', 'catalina', 'catalina', 'catalina', 'correrías', 'catalina', 'o', 'catalina', 'catalina', 'manzanos', 'ostentaban', 'catalina', 'catalina', 'labrador', 'o', 'francia', 'vertida', 'o', 'o', 'según', 'taberna', 'taberna', 'taberna', 'o', 'varita', 'monstruosas', 'lobos', 'o', 'aullar', 'o', 'o', 'o', 'o', 'apartó', 'garras', 'débiles', 'según', 'párroco', 'niñera', 'francia', 'bárbaro', 'pescante', 'catalina', 'francia', 'catalina', 'francia', 'débiles', 'francia', 'galgo', 'o', 'catalina', 'o', 'catalina', 'según', 'taberna', 'doncella', 'catalina', 'catalina', 'profesaba', 'catalina', 'zurdo', 'torpemente', 'catalina', 'catalina', 'o', 'panadero', 'manzanos', 'catalina', 'bromeando', 'catalina', 'superioridad', 'vagabundo', 'ladrón', 'catalina', 'ladrón', 'catalina', 'catalina', 'catalina', 'catalina', 'correrías', 'o', 'o', 'o', 'panadero', 'palmo', 'palmo', 'francia', 'retórica', 'vera', 'catalina', 'vera', 'vera', 'francia', 'catalina', 'tempestad', 'cabaña', 'o', 'antorcha', 'lumbre', 'desobedecían', 'francia', 'fueros', 'roma', 'republicano', 'ilustrado', 'o', 'o', 'vericuetos', 'o', 'vera', 'vera', 'francia', 'posadero', 'vera', 'o', 'catalina', 'catalina', 'catalina', 'catalina', 'catalina', 'débil', 'catalina', 'catalina', 'estrechó', 'o', 'o', 'o', 'o', 'aparentando', 'vera', 'cesto', 'suplicante', 'o', 'agonía', 'capitaneaba', 'fenomenal', 'mocetón', 'o', 'cordero', 'taberna', 'ostentaba', 'según', 'mazorcas', 'amablemente', 'sanguinarios', 'bárbaro', 'según', 'fríamente', 'bárbaro', 'posadero', 'posadero', 'mendigo', 'posadero', 'o', 'o', 'o', 'o', 'o', 'desafió', 'o', 'o', 'aun', 'músico', 'per', 'per', 'o', 'párroco', 'fríamente', 'taberna', 'retóricas', 'sendas', 'apretones', 'dentadura', 'reñido', 'ayer', 'o', 'finura', 'o', 'músico', 'músico', 'fugitivos', 'fríamente', 'o', 'fugitivos', 'manzanos', 'o', 'manzanos', 'débil', 'débil', 'o', 'convalecencia', 'francia', 'convalecencia', 'o', 'catalina', 'delirio', 'estrechó', 'veras', 'francia', 'mechero', 'tabernas', 'taberna', 'taberna', 'taberna', 'vera', 'catalina', 'taberna', 'rabiaban', 'hélice', 'taberna', 'o', 'o', 'francia', 'o', 'o', 'ocre', 'bordeando', 'fernando', 'lumbre', 'moscas', 'moscas', 'moscas', 'posadero', 'moscas', 'moscas', 'gracioso', 'fernando', 'fernando', 'fernando', 'fernando', 'según', 'fernando', 'fernando', 'fernando', 'fernando', 'despensa', 'fernando', 'fernando', 'redonda', 'fernando', 'o', 'fernando', 'gatos', 'gato', 'fernando', 'gato', 'gatos', 'fernando', 'fernando', 'fernando', 'cortejar', 'fernando', 'fernando', 'rellenó', 'fernando', 'fernando', 'fernando', 'fernando', 'fernando', 'fernando', 'bordeaba', 'fernando', 'fernando', 'garras', 'desnivel', 'alcoba', 'o', 'tranquilizadores', 'o', 'o', 'francia', 'o', 'mecheros', 'o', 'franqueza', 'según', 'ladrones', 'tabernas', 'falsificación', 'rencores', 'garras', 'gracioso', 'o', 'caldo', 'ladrón', 'alcobas', 'lamentos', 'alcoba', 'alcoba', 'ladrón', 'alcoba', 'catalina', 'majestad', 'o', 'catalina', 'catalina', 'catalina', 'catalina', 'galope', 'amablemente', 'equivocación', 'cerrojo', 'aun', 'o', 'cerrojo', 'perseguidores', 'lujoso', 'ayer', 'catalina', 'catalina', 'catalina', 'pescante', 'patrulla', 'catalina', 'catalina', 'pescante', 'posadero', 'posadero', 'estrechó', 'pescante', 'patrulla', 'anciano', 'patrulla', 'galope', 'galope', 'catalina', 'perseguidores', 'perseguidores', 'afinaban', 'pescante', 'galope', 'o', 'pescante', 'catalina', 'pescante', 'excitado', 'revueltos', 'catalina', 'lamentos', 'catalina', 'militarmente', 'estupor', 'catalina', 'catalina', 'catalina', 'catalina', 'espolón', 'equivocación', 'o', 'convalecencias', 'catalina', 'catalina', 'fuero', 'catalina', 'catalina', 'fonda', 'catalina', 'catalina', 'catalina', 'catalina', 'polígono', 'famélico', 'según', 'o', 'o', 'enfilar', 'olivares', 'o', 'catalina', 'catalina', 'inflexible', 'catalina', 'catalina', 'redonda', 'leña', 'monótona', 'francia', 'catalina', 'catalina', 'inercia', 'veras', 'catalina', 'mendigo', 'pucheros', 'estrecharon', 'defendido', 'sendas', 'francia', 'catalina', 'francia', 'catalina', 'catalina', 'blancura', 'bordea', 'humedecida', 'soñador', 'o', 'descargas', 'o', 'francia', 'catalina', 'o', 'avaricia', 'catalina', 'o', 'catalina', 'catalina', 'o', 'catalina', 'catalina', 'catalina', 'catalina', 'clarín', 'catalina', 'fonda', 'labradores', 'catalina', 'bárbaras', 'alero', 'ostenta', 'débiles', 'eterna', 'labradores', 'catalina']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally just a few functions to organize the data: get rid of duplicates and organize by frequency and then write all that to a text file"
      ],
      "metadata": {
        "id": "lxakcWuzX6-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert filtered words list to panda data frame\n",
        "filtered_df = pd.DataFrame(filtered_words, columns=['word'])\n",
        "\n",
        "# get rid of duplicates\n",
        "filtered_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# order by freq\n",
        "filtered_df = filtered_df.merge(df, how = 'left', left_on = 'word', right_on = 'lemma')\n",
        "filtered_df.sort_values(by = 'freq', ascending = True, inplace = True)\n",
        "\n",
        "# write to a text file\n",
        "output_file = \"B2_word_list.txt\"\n",
        "with open(output_file, \"w\", encoding = \"utf-8\") as file:\n",
        "    for word in zip(filtered_df['word']):\n",
        "        file.write(f\"{word}\\n\")\n"
      ],
      "metadata": {
        "id": "eCtDAf8eX7XS"
      },
      "execution_count": 131,
      "outputs": []
    }
  ]
}